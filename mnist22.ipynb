{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KomaliValluru/DS/blob/main/mnist22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDwNAZEY9Xgr"
      },
      "source": [
        "The MNIST database of handwritten digits.\n",
        "\n",
        "label\n",
        "call_split\n",
        "bar_chart\n",
        "70,000 items\n",
        "Value\n",
        "arrow_drop_up\n",
        "Count\n",
        "0\n",
        "6,903\n",
        "1\n",
        "7,877\n",
        "2\n",
        "6,990\n",
        "3\n",
        "7,141\n",
        "4\n",
        "6,824\n",
        "5\n",
        "6,313\n",
        "6\n",
        "6,876\n",
        "7\n",
        "7,293\n",
        "8\n",
        "6,825\n",
        "9\n",
        "6,958\n",
        "split\n",
        "call_split\n",
        "bar_chart\n",
        "70,000 items\n",
        "Value\n",
        "arrow_drop_up\n",
        "Count\n",
        "test\n",
        "10,000\n",
        "train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9hmDV_k1elA"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# You cannot modify from here until it is indicated by a comment\n",
        "(test_data),test_data_info=tfds.load('mnist',split='test',with_info=True,as_supervised=True)\n",
        "\n",
        "(train_data),ds_info=tfds.load('mnist',split=['train[10000:45000]'],with_info=True,as_supervised=True)\n",
        "\n",
        "def getnewtst():\n",
        "  (new_test),new_test_info=tfds.load('mnist',split=['train[0:9999]'],with_info=True,as_supervised=True)\n",
        "  new_test = new_test[0].map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  new_test = new_test.batch(64)\n",
        "  new_test = new_test.cache()\n",
        "  new_test = new_test.prefetch(tf.data.AUTOTUNE)\n",
        "  return new_test\n",
        "\n",
        "\n",
        "# Can modify code now below this comment\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\n",
        "  The model wants the float and tfds gives you 0-255.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "\n",
        "train_data = train_data[0].map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_data = train_data.cache()\n",
        "train_data = train_data.shuffle(ds_info.splits['train'].num_examples)\n",
        "train_data = train_data.batch(64)\n",
        "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "test_data = test_data.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_data = test_data.batch(128)\n",
        "test_data = test_data.cache()\n",
        "test_data = test_data.prefetch(tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcNXigc06Am4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4d9119-bed6-4dd8-f12b-7fce3255b7c8"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 ),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=2, padding='same',\n",
        "                 activation='relu'\n",
        "                 ),\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(momentum=0.3,learning_rate=0.08),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    epochs=7,\n",
        "    validation_data=test_data,\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "547/547 [==============================] - 43s 75ms/step - loss: 0.1559 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 2/7\n",
            "547/547 [==============================] - 40s 72ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9821\n",
            "Epoch 3/7\n",
            "547/547 [==============================] - 40s 72ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.0433 - val_sparse_categorical_accuracy: 0.9855\n",
            "Epoch 4/7\n",
            "547/547 [==============================] - 40s 73ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.0545 - val_sparse_categorical_accuracy: 0.9819\n",
            "Epoch 5/7\n",
            "547/547 [==============================] - 40s 73ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0457 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 6/7\n",
            "547/547 [==============================] - 41s 76ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9864\n",
            "Epoch 7/7\n",
            "547/547 [==============================] - 40s 74ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0401 - val_sparse_categorical_accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ab4ae5d60>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuMHiN8-D3Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7f7ead-252e-4cad-b780-3814d429a2c4"
      },
      "source": [
        "\n",
        "results = model.evaluate(getnewtst())\n",
        "print(\"test loss, test acc:\", results)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 4s 27ms/step - loss: 0.0512 - sparse_categorical_accuracy: 0.9866\n",
            "test loss, test acc: [0.05123588442802429, 0.9865986704826355]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYumdS0lXXpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}